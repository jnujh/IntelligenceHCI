package com.chatbot.voicebot.controller;

import com.chatbot.voicebot.service.WhisperService;
import com.chatbot.voicebot.service.GptService;
import com.chatbot.voicebot.service.TtsService;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.core.io.ByteArrayResource;
import org.springframework.core.io.Resource;
import org.springframework.http.MediaType;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;
import org.springframework.web.multipart.MultipartFile;

@Slf4j
@RestController
@RequestMapping("/api")
@RequiredArgsConstructor
public class VoiceChatController {

    private final WhisperService whisperService;
    private final GptService gptService;
    private final TtsService ttsService;

    @PostMapping("/stt")
    public ResponseEntity<Resource> handleVoice(
            @RequestParam("audio") MultipartFile audioFile,
            @RequestParam("voice") String voiceStyle
    ) throws Exception {

        log.info("â–¶ ìŒì„± íŒŒì¼ ìˆ˜ì‹ : {}, ë§íˆ¬: {}", audioFile.getOriginalFilename(), voiceStyle);

        // 1. ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜ (STT)
        String userText = whisperService.transcribe(audioFile);
        log.info("ğŸ—£ï¸ STT ê²°ê³¼: {}", userText);

        // 2. GPT ì‘ë‹µ ìƒì„±
        String gptResponse = gptService.ask(userText);
        log.info("ğŸ’¬ GPT ì‘ë‹µ: {}", gptResponse);

        // 3. TTS ìŒì„± ìƒì„±
        byte[] audioBytes = ttsService.speak(gptResponse, voiceStyle);
        log.info("ğŸ”Š TTS ìŒì„± ìƒì„± ì™„ë£Œ ({} bytes)", audioBytes.length);

        // 4. ìŒì„± íŒŒì¼ ë°˜í™˜
        return ResponseEntity.ok()
                .contentType(MediaType.parseMediaType("audio/wav"))
                .body(new ByteArrayResource(audioBytes));
    }
}
